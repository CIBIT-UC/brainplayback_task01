{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM analysis on the main tasks\n",
    "It uses nilearn and performs the following steps:\n",
    "1. Load the data from fmriPrep in BIDS format\n",
    "2. Iterate on the subjects to:\n",
    "   1. Select the predictors and confounds for the design matrix\n",
    "   2. Generate 1st level model\n",
    "   3. Estimate contrast maps\n",
    "3. Generate group level maps\n",
    "4. Generate hMT+ mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "from nilearn.interfaces.bids import save_glm_to_bids\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn.image import math_img\n",
    "from nilearn.masking import apply_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "data_dir = '/DATAPOOL/BRAINPLAYBACK/BIDS-BRAINPLAYBACK-TASK1/'\n",
    "space_label = \"MNI152NLin2009cAsym\"\n",
    "derivatives_folder = \"derivatives/fmriprep/fmriprep\"\n",
    "task_label = \"01\"\n",
    "smoothing_fwhm = 4.0\n",
    "high_pass_hz = 0.007\n",
    "out_dir = os.path.join(data_dir,\"derivatives\",\"nilearn_glm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data from fmriPrep in BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import first level data automatically from fmriPrep derivatives\n",
    "(\n",
    "    models,\n",
    "    models_run_imgs,\n",
    "    models_events,\n",
    "    models_confounds,\n",
    ") = first_level_from_bids(\n",
    "    data_dir,\n",
    "    task_label,\n",
    "    space_label,\n",
    "    hrf_model=\"spm\",\n",
    "    noise_model=\"ar2\",\n",
    "    smoothing_fwhm=smoothing_fwhm,\n",
    "    high_pass=high_pass_hz,\n",
    "    slice_time_ref=None,\n",
    "    n_jobs=8,\n",
    "    minimize_memory = False,\n",
    "    derivatives_folder=derivatives_folder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit all models_events to exclude the conditions that end with '_p'\n",
    "for ii in range(len(models_events)):\n",
    "    for jj in range(len(models_events[ii])):\n",
    "        models_events[ii][jj] = models_events[ii][jj][models_events[ii][jj].trial_type.str.endswith('_p') == False]\n",
    "\n",
    "models_events[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deal with contrast names\n",
    "These should be balanced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition names\n",
    "condition_names = ['Q1_db','Q2_db','Q3_db','Q4_db']\n",
    "\n",
    "# create strings for contrasts in the format of \"condition_name - Noise\"\n",
    "contrasts = []\n",
    "\n",
    "# add contrast all conditions vs. noise\n",
    "contrasts.append(\"Q1_db + Q2_db + Q3_db + Q4_db - Noise*4\")\n",
    "\n",
    "# iterate to add the other contrasts\n",
    "for condition in condition_names:\n",
    "    contrasts.append(condition + \" - Noise\")\n",
    "\n",
    "# add more contrasts based on the arousal and valence\n",
    "contrasts.append(\"Q1_db*0.5 + Q2_db*0.5 - Q3_db*0.5 - Q4_db*0.5\") # positive arousal vs. negative arousal\n",
    "contrasts.append(\"Q1_db*0.5 + Q4_db*0.5 - Q3_db*0.5 - Q2_db*0.5\") # positive valence vs. negative valence\n",
    "\n",
    "contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to use the contrasts as names for the output files\n",
    "contrasts_renamed = ['Q1234MinusNoise',\n",
    "                     'Q1MinusNoise',\n",
    "                     'Q2MinusNoise',\n",
    "                     'Q3MinusNoise',\n",
    "                     'Q4MinusNoise',\n",
    "                     'PositiveArousalMinusNegativeArousal',\n",
    "                     'PositiveValenceMinusNegativeValence']\n",
    "\n",
    "contrasts_renamed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Iterate on the subjects\n",
    "This was computed in the INCD cluster for speed :) It takes a while, as it estimated the multi-run GLM for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(models)):\n",
    "\n",
    "    # fetch model\n",
    "    model, imgs, events, confounds = (\n",
    "        models[idx],\n",
    "        models_run_imgs[idx],\n",
    "        models_events[idx],\n",
    "        models_confounds[idx],\n",
    "    )\n",
    "\n",
    "    subject = f\"sub-{model.subject_label}\"\n",
    "\n",
    "    print(f\"Computing 1st level model for subject: {subject}\")\n",
    "\n",
    "    # trim confounds and replace NaNs with 0\n",
    "    for ii in range(len(confounds)):\n",
    "        confounds[ii] = confounds[ii][['trans_x', 'trans_x_derivative1', 'trans_x_power2', 'trans_x_derivative1_power2',\n",
    "                                        'trans_y', 'trans_y_derivative1', 'trans_y_power2', 'trans_y_derivative1_power2',\n",
    "                                        'trans_z', 'trans_z_derivative1', 'trans_z_power2', 'trans_z_derivative1_power2',\n",
    "                                        'rot_x', 'rot_x_derivative1', 'rot_x_power2', 'rot_x_derivative1_power2',\n",
    "                                        'rot_y', 'rot_y_derivative1', 'rot_y_power2', 'rot_y_derivative1_power2',\n",
    "                                        'rot_z', 'rot_z_derivative1', 'rot_z_power2', 'rot_z_derivative1_power2',\n",
    "                                            ]]\n",
    "    \n",
    "        confounds[ii] = confounds[ii].fillna(0)\n",
    "    \n",
    "    # Fit and contrasts\n",
    "    model.fit(imgs, events, confounds)\n",
    "\n",
    "    # create and save z_map, t_map, and beta_map to nifti files for every contrast\n",
    "    for ii in range(len(contrasts)):\n",
    "\n",
    "        z_map = model.compute_contrast(contrasts[ii], output_type=\"z_score\")\n",
    "        t_map = model.compute_contrast(contrasts[ii], output_type=\"stat\")\n",
    "        beta_map = model.compute_contrast(contrasts[ii], output_type=\"effect_size\")\n",
    "\n",
    "        z_map.to_filename(os.path.join(out_dir, f\"{subject}_task-{task_label}_stat-z_con-{contrasts_renamed[ii]}.nii.gz\"))\n",
    "        t_map.to_filename(os.path.join(out_dir, f\"{subject}_task-{task_label}_stat-t_con-{contrasts_renamed[ii]}.nii.gz\"))\n",
    "        beta_map.to_filename(os.path.join(out_dir, f\"{subject}_task-{task_label}_stat-beta_con-{contrasts_renamed[ii]}.nii.gz\"))\n",
    "\n",
    "        # create figure with thresholded map for fun\n",
    "        clean_map, threshold = threshold_stats_img(\n",
    "            z_map, alpha=0.05, height_control=\"bonferroni\", cluster_threshold=25\n",
    "        )\n",
    "\n",
    "        plotting.plot_glass_brain(\n",
    "            clean_map,\n",
    "            colorbar=True,\n",
    "            threshold=threshold,\n",
    "            plot_abs=False,\n",
    "            display_mode=\"ortho\",\n",
    "            figure=plt.figure(figsize=(10, 4)),\n",
    "        )\n",
    "\n",
    "        plt.savefig(os.path.join(\n",
    "            out_dir,\n",
    "            f\"{subject}_task-{task_label}_plot-z_con-{contrasts_renamed[ii]}_c-bonferroni_p-0.05_clusterk-25.png\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Export cluster table\n",
    "        table = get_clusters_table(z_map, threshold, 25)\n",
    "        table.to_csv(os.path.join(\n",
    "            out_dir,\n",
    "            f\"{subject}_task-{task_label}_table-clusters_con-{contrasts_renamed[ii]}_c-bonferroni_p-0.05_clusterk-25.tsv\"\n",
    "            ),\n",
    "            sep='\\t'\n",
    "        )\n",
    "\n",
    "    # Attempt to free memory\n",
    "    del model, imgs, events, confounds\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Group level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just some paths again\n",
    "out_dir = os.path.join(data_dir,\"derivatives\",\"nilearn_glm\")\n",
    "out_dir_group = os.path.join(data_dir,\"derivatives\",\"nilearn_glm\",\"group\")\n",
    "if not os.path.exists(out_dir_group):\n",
    "    os.makedirs(out_dir_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a contrast\n",
    "c_idx = 0\n",
    "\n",
    "# List all tmap nii.gz files\n",
    "tmap_files = glob.glob(\n",
    "    os.path.join(out_dir,\n",
    "        f\"sub-*_task-{task_label}_stat-t_con-{contrasts_renamed[c_idx]}.nii.gz\"\n",
    "    )\n",
    ")\n",
    "tmap_files.sort()\n",
    "\n",
    "# List all zmap nii.gz files\n",
    "zmap_files = glob.glob(\n",
    "    os.path.join(out_dir,\n",
    "        f\"sub-*_task-{task_label}_stat-z_con-{contrasts_renamed[c_idx]}.nii.gz\"\n",
    "    )\n",
    ")\n",
    "zmap_files.sort()\n",
    "\n",
    "subject_list = [os.path.basename(f).split('_')[0] for f in tmap_files]\n",
    "subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: plot_glass_matrix_singlesubject\n",
    "\n",
    "# Plot all subjects t_maps for a given contrast\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(10, 10))\n",
    "\n",
    "for cidx, tmap in enumerate(tmap_files):\n",
    "    P = plotting.plot_glass_brain(\n",
    "        tmap,\n",
    "        colorbar=True,\n",
    "        threshold=6.0,\n",
    "        vmax=25,\n",
    "        axes=axes[cidx % 4, int(cidx / 4)],\n",
    "        plot_abs=False,\n",
    "        display_mode=\"x\",\n",
    "    )\n",
    "    P.title(subject_list[cidx], size=8)\n",
    "\n",
    "fig.suptitle(f\"subjects t_map for contrast {contrasts[c_idx]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix for 2nd level\n",
    "second_level_input = zmap_files\n",
    "design_matrix_g = pd.DataFrame(\n",
    "    [1] * len(second_level_input),\n",
    "    columns=[\"intercept\"],\n",
    ")\n",
    "\n",
    "# define 2nd level model\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=6.0, n_jobs=12)\n",
    "second_level_model.minimize_memory = False\n",
    "second_level_model = second_level_model.fit(\n",
    "    second_level_input,\n",
    "    design_matrix=design_matrix_g,\n",
    ")\n",
    "\n",
    "# compute contrast (z score map)\n",
    "z_map_g = second_level_model.compute_contrast(\n",
    "    second_level_contrast=\"intercept\",\n",
    "    output_type=\"z_score\",\n",
    ")\n",
    "\n",
    "# compute contrast (t score map)\n",
    "t_map_g = second_level_model.compute_contrast(\n",
    "    second_level_contrast=\"intercept\",\n",
    "    output_type=\"stat\",\n",
    ")\n",
    "\n",
    "# compute contrast (beta map)\n",
    "beta_map_g = second_level_model.compute_contrast(\n",
    "    second_level_contrast=\"intercept\",\n",
    "    output_type='effect_size',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold zmap and plot it\n",
    "hc = None # None, 'bonferroni', 'fdr'\n",
    "ct = 25 # cluster threshold\n",
    "alpha = 0.001 # p-value threshold\n",
    "\n",
    "clean_map_g, threshold_g = threshold_stats_img(\n",
    "    z_map_g, alpha=alpha, height_control=hc, cluster_threshold=ct\n",
    ")\n",
    "\n",
    "plotting.plot_glass_brain(\n",
    "    clean_map_g,\n",
    "    colorbar=True,\n",
    "    threshold=threshold_g,\n",
    "    plot_abs=False,\n",
    "    display_mode=\"ortho\",\n",
    "    vmax=8,\n",
    "    figure=plt.figure(figsize=(10, 4)),\n",
    "    symmetric_cbar=False,\n",
    "    cmap=nilearn_cmaps[\"cold_hot\"],\n",
    ")\n",
    "\n",
    "plt.savefig(os.path.join(out_dir_group,\n",
    "                         f\"group_task-{task_label}_plot-z_con-_{contrasts_renamed[c_idx]}_c-{hc}_p-{alpha}_clusterk-{ct}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cluster table\n",
    "table_g,cluster_map_g = get_clusters_table(z_map_g, threshold_g, ct,\n",
    "                                return_label_maps=True)\n",
    "\n",
    "table_g.to_csv(os.path.join(out_dir_group,\n",
    "                          f\"group_task-{task_label}_table-clusters_con-{contrasts_renamed[c_idx]}_c-{hc}_p-0.05_clusterk-{ct}.tsv\"),sep='\\t')\n",
    "#print(table)\n",
    "#print(table.to_latex())\n",
    "table_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View map interactively\n",
    "plotting.view_img(clean_map_g,\n",
    "         threshold=threshold_g\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: loc_group_interactive\n",
    "# Show cluster_map_g\n",
    "plotting.view_img(cluster_map_g[0],\n",
    "                  vmax=3, vmin=0,\n",
    "                  resampling_interpolation='nearest',\n",
    "                  cmap='hot',\n",
    "                  symmetric_cmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values in cluster_map_g[0]\n",
    "np.unique(cluster_map_g[0].get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate auditory cluster mask as an example\n",
    "# in this case, it is values 1 and 2 from cluster_map_g\n",
    "aux_mask1 = math_img('img == 3', img=cluster_map_g[0])\n",
    "aux_mask2 = math_img('img == 5', img=cluster_map_g[0])\n",
    "mask_hMT = math_img('img1 + img2', img1=aux_mask1, img2=aux_mask2)\n",
    "\n",
    "plotting.view_img(mask_hMT, vmax=1, vmin=0, symmetric_cmap=False, cmap='hot')\n",
    "\n",
    "# save mask\n",
    "#mask_hMT.to_filename(os.path.join(data_dir,\"derivatives\",\"nilearn_glm\",\"group\",'mask_hMT.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch map values inside mask_hMT  \n",
    "# Apply mask to z_map_g\n",
    "z_map_hMT = apply_mask(z_map_g, mask_hMT)\n",
    "\n",
    "# Apply mask to beta_map_g\n",
    "beta_map_hMT = apply_mask(beta_map_g, mask_hMT)\n",
    "\n",
    "# Estimate mean of z_map_hMT\n",
    "z_map_hMT_mean = np.mean(z_map_hMT)\n",
    "\n",
    "z_map_hMT_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpmb-tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
